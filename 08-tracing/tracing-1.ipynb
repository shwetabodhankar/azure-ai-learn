{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observability and Tracing with Manual OpenTelemetry\n",
    "\n",
    "This notebook demonstrates how to implement tracing using the Microsoft Learn approach with explicit OpenTelemetry configuration and manual span creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "\n",
    "from agent_framework import Executor, WorkflowBuilder, WorkflowContext, handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartExecutor(Executor):\n",
    "    @handler  # type: ignore[misc]\n",
    "    async def handle_input(self, message: str, ctx: WorkflowContext[str]) -> None:\n",
    "        tracer = trace.get_tracer(__name__)\n",
    "        with tracer.start_as_current_span(\"start_executor_process\") as span:\n",
    "            span.set_attribute(\"input.message\", message)\n",
    "            span.set_attribute(\"executor.id\", \"start\")\n",
    "            \n",
    "            try:\n",
    "                # Transform and forward downstream\n",
    "                result = message.upper()\n",
    "                span.set_attribute(\"output.message\", result)\n",
    "                await ctx.send_message(result)\n",
    "                span.set_status(Status(StatusCode.OK))\n",
    "            except Exception as e:\n",
    "                span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "                span.record_exception(e)\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndExecutor(Executor):\n",
    "    @handler  # type: ignore[misc]\n",
    "    async def handle_final(self, message: str, ctx: WorkflowContext) -> None:\n",
    "        tracer = trace.get_tracer(__name__)\n",
    "        with tracer.start_as_current_span(\"end_executor_process\") as span:\n",
    "            span.set_attribute(\"final.message\", message)\n",
    "            span.set_attribute(\"executor.id\", \"end\")\n",
    "            \n",
    "            try:\n",
    "                print(f\"Final result: {message}\")\n",
    "                span.set_status(Status(StatusCode.OK))\n",
    "            except Exception as e:\n",
    "                span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "                span.record_exception(e)\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    # Configure Azure Monitor with explicit connection string\n",
    "    connection_string = os.getenv('APPLICATIONINSIGHTS_CONNECTION_STRING')\n",
    "    if connection_string:\n",
    "        configure_azure_monitor(connection_string=connection_string)\n",
    "        print(\"Azure Monitor configured successfully\")\n",
    "    else:\n",
    "        print(\"Warning: No Application Insights connection string found\")\n",
    "        print(\"Falling back to console exporter for local development\")\n",
    "        # You could fall back to console exporter for local development\n",
    "        from opentelemetry.sdk.trace import TracerProvider\n",
    "        from opentelemetry.sdk.trace.export import ConsoleSpanExporter, BatchSpanProcessor\n",
    "        trace.set_tracer_provider(TracerProvider())\n",
    "        trace.get_tracer_provider().add_span_processor(\n",
    "            BatchSpanProcessor(ConsoleSpanExporter())\n",
    "        )\n",
    "    \n",
    "    tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    with tracer.start_as_current_span(\"workflow_execution\") as workflow_span:\n",
    "        workflow_span.set_attribute(\"workflow.type\", \"simple_pipeline\")\n",
    "        workflow_span.set_attribute(\"workflow.nodes\", 2)\n",
    "        \n",
    "        try:\n",
    "            # Build workflow with explicit tracing\n",
    "            with tracer.start_as_current_span(\"workflow_build\") as build_span:\n",
    "                workflow = (\n",
    "                    WorkflowBuilder()\n",
    "                    .add_edge(StartExecutor(id=\"start\"), EndExecutor(id=\"end\"))\n",
    "                    .set_start_executor(\"start\")\n",
    "                    .build()\n",
    "                )\n",
    "                build_span.set_status(Status(StatusCode.OK))\n",
    "                print(\"Workflow built successfully\")\n",
    "            \n",
    "            # Run workflow with explicit tracing\n",
    "            with tracer.start_as_current_span(\"workflow_run\") as run_span:\n",
    "                input_message = \"We are demonstrating Tracing to DVC\"\n",
    "                run_span.set_attribute(\"input.message\", input_message)\n",
    "                \n",
    "                print(f\"Running workflow with input: {input_message}\")\n",
    "                await workflow.run(input_message)\n",
    "                run_span.set_status(Status(StatusCode.OK))\n",
    "                print(\"Workflow completed successfully\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            workflow_span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            workflow_span.record_exception(e)\n",
    "            print(f\"Error during workflow execution: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced main function with client requests and interactive prompts\n",
    "async def main_with_client() -> None:\n",
    "    \"\"\"Enhanced main function that creates a client and makes trackable requests\"\"\"\n",
    "    import time\n",
    "    \n",
    "    # Configure Azure Monitor with explicit connection string\n",
    "    connection_string = os.getenv('APPLICATIONINSIGHTS_CONNECTION_STRING')\n",
    "    if connection_string:\n",
    "        configure_azure_monitor(connection_string=connection_string)\n",
    "        print(\"‚úÖ Azure Monitor configured successfully\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Warning: No Application Insights connection string found\")\n",
    "        print(\"üîÑ Falling back to console exporter for local development\")\n",
    "        from opentelemetry.sdk.trace import TracerProvider\n",
    "        from opentelemetry.sdk.trace.export import ConsoleSpanExporter, BatchSpanProcessor\n",
    "        trace.set_tracer_provider(TracerProvider())\n",
    "        trace.get_tracer_provider().add_span_processor(\n",
    "            BatchSpanProcessor(ConsoleSpanExporter())\n",
    "        )\n",
    "    \n",
    "    tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    # Get user input for requests\n",
    "    print(\"\\nüéØ Interactive Tracing Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Prompt for number of requests\n",
    "    try:\n",
    "        num_requests = int(input(\"How many requests would you like to make? (1-5): \") or \"3\")\n",
    "        num_requests = min(max(1, num_requests), 5)  # Limit between 1-5\n",
    "    except ValueError:\n",
    "        num_requests = 3\n",
    "        print(f\"Invalid input, using default: {num_requests}\")\n",
    "    \n",
    "    # Prompt for request type\n",
    "    request_type = input(\"\"\"\n",
    "Select request type:\n",
    "1. Text transformation\n",
    "2. Data processing\n",
    "3. Business logic simulation\n",
    "4. Custom workflow\n",
    "\n",
    "Enter choice (1-4): \"\"\").strip() or \"1\"\n",
    "    \n",
    "    # Map request types\n",
    "    request_types = {\n",
    "        \"1\": \"text_transformation\",\n",
    "        \"2\": \"data_processing\", \n",
    "        \"3\": \"business_logic\",\n",
    "        \"4\": \"custom_workflow\"\n",
    "    }\n",
    "    \n",
    "    selected_type = request_types.get(request_type, \"text_transformation\")\n",
    "    print(f\"üöÄ Selected: {selected_type}\")\n",
    "    \n",
    "    with tracer.start_as_current_span(\"client_session\") as session_span:\n",
    "        session_span.set_attribute(\"session.type\", selected_type)\n",
    "        session_span.set_attribute(\"session.request_count\", num_requests)\n",
    "        session_span.set_attribute(\"session.start_time\", time.time())\n",
    "        \n",
    "        try:\n",
    "            # Build workflow\n",
    "            with tracer.start_as_current_span(\"workflow_initialization\") as init_span:\n",
    "                workflow = (\n",
    "                    WorkflowBuilder()\n",
    "                    .add_edge(StartExecutor(id=\"start\"), EndExecutor(id=\"end\"))\n",
    "                    .set_start_executor(\"start\")\n",
    "                    .build()\n",
    "                )\n",
    "                init_span.set_status(Status(StatusCode.OK))\n",
    "                print(\"‚úÖ Workflow initialized successfully\")\n",
    "            \n",
    "            # Process multiple requests\n",
    "            results = []\n",
    "            for i in range(num_requests):\n",
    "                with tracer.start_as_current_span(f\"client_request_{i+1}\") as request_span:\n",
    "                    # Get user input for each request\n",
    "                    if selected_type == \"text_transformation\":\n",
    "                        user_input = input(f\"\\nRequest {i+1} - Enter text to transform: \") or f\"Sample text {i+1}\"\n",
    "                        expected_output = user_input.upper()\n",
    "                    elif selected_type == \"data_processing\":\n",
    "                        user_input = input(f\"\\nRequest {i+1} - Enter data to process: \") or f\"data_item_{i+1}\"\n",
    "                        expected_output = f\"PROCESSED_{user_input}\"\n",
    "                    elif selected_type == \"business_logic\":\n",
    "                        user_input = input(f\"\\nRequest {i+1} - Enter business scenario: \") or f\"scenario_{i+1}\"\n",
    "                        expected_output = f\"BUSINESS_RESULT_{user_input.upper()}\"\n",
    "                    else:\n",
    "                        user_input = input(f\"\\nRequest {i+1} - Enter custom input: \") or f\"custom_input_{i+1}\"\n",
    "                        expected_output = user_input.upper()\n",
    "                    \n",
    "                    # Add request attributes\n",
    "                    request_span.set_attribute(\"request.number\", i+1)\n",
    "                    request_span.set_attribute(\"request.input\", user_input)\n",
    "                    request_span.set_attribute(\"request.input_length\", len(user_input))\n",
    "                    request_span.set_attribute(\"request.type\", selected_type)\n",
    "                    request_span.set_attribute(\"request.timestamp\", time.time())\n",
    "                    \n",
    "                    print(f\"üîÑ Processing request {i+1}: '{user_input}'\")\n",
    "                    \n",
    "                    try:\n",
    "                        # Process the request through workflow\n",
    "                        start_time = time.time()\n",
    "                        await workflow.run(user_input)\n",
    "                        end_time = time.time()\n",
    "                        \n",
    "                        # Record successful result\n",
    "                        processing_time = end_time - start_time\n",
    "                        request_span.set_attribute(\"request.processing_time_ms\", processing_time * 1000)\n",
    "                        request_span.set_attribute(\"request.status\", \"success\")\n",
    "                        request_span.set_attribute(\"request.expected_output\", expected_output)\n",
    "                        request_span.set_status(Status(StatusCode.OK))\n",
    "                        \n",
    "                        results.append({\n",
    "                            \"request_id\": i+1,\n",
    "                            \"input\": user_input,\n",
    "                            \"expected_output\": expected_output,\n",
    "                            \"processing_time\": processing_time,\n",
    "                            \"status\": \"success\"\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"‚úÖ Request {i+1} completed in {processing_time*1000:.2f}ms\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        # Record error\n",
    "                        request_span.set_attribute(\"request.status\", \"error\")\n",
    "                        request_span.set_attribute(\"request.error_message\", str(e))\n",
    "                        request_span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "                        request_span.record_exception(e)\n",
    "                        \n",
    "                        results.append({\n",
    "                            \"request_id\": i+1,\n",
    "                            \"input\": user_input,\n",
    "                            \"status\": \"error\",\n",
    "                            \"error\": str(e)\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"‚ùå Request {i+1} failed: {e}\")\n",
    "            \n",
    "            # Session summary\n",
    "            session_span.set_attribute(\"session.end_time\", time.time())\n",
    "            session_span.set_attribute(\"session.total_requests\", len(results))\n",
    "            session_span.set_attribute(\"session.successful_requests\", sum(1 for r in results if r[\"status\"] == \"success\"))\n",
    "            session_span.set_attribute(\"session.failed_requests\", sum(1 for r in results if r[\"status\"] == \"error\"))\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"\\nüìä Session Summary:\")\n",
    "            print(f\"   Total requests: {len(results)}\")\n",
    "            print(f\"   Successful: {sum(1 for r in results if r['status'] == 'success')}\")\n",
    "            print(f\"   Failed: {sum(1 for r in results if r['status'] == 'error')}\")\n",
    "            \n",
    "            if any(r[\"status\"] == \"success\" for r in results):\n",
    "                avg_time = sum(r.get(\"processing_time\", 0) for r in results if r[\"status\"] == \"success\") / sum(1 for r in results if r[\"status\"] == \"success\")\n",
    "                print(f\"   Average processing time: {avg_time*1000:.2f}ms\")\n",
    "                session_span.set_attribute(\"session.average_processing_time_ms\", avg_time * 1000)\n",
    "            \n",
    "            session_span.set_status(Status(StatusCode.OK))\n",
    "            print(\"üéâ Client session completed successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            session_span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            session_span.record_exception(e)\n",
    "            print(f\"‚ùå Session failed: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the enhanced main function with client interactions\n",
    "print(\"üöÄ Starting interactive client session...\")\n",
    "await main_with_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Request Simulation\n",
    "\n",
    "The enhanced main function now includes:\n",
    "\n",
    "- **Interactive Prompts**: Users can specify the number and type of requests\n",
    "- **Request Types**: Text transformation, data processing, business logic, or custom workflows\n",
    "- **Input/Output Logging**: Each request logs input, expected output, processing time, and status\n",
    "- **Session Tracking**: Overall session metrics including success rates and performance\n",
    "- **Detailed Spans**: Each request creates its own span with comprehensive attributes\n",
    "\n",
    "### Traced Attributes Include:\n",
    "- `request.input` - User input data\n",
    "- `request.input_length` - Length of input\n",
    "- `request.processing_time_ms` - Time taken to process\n",
    "- `request.status` - Success or error status\n",
    "- `session.request_count` - Total requests in session\n",
    "- `session.average_processing_time_ms` - Average processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Automated client requests for testing\n",
    "async def automated_client_demo():\n",
    "    \"\"\"Run automated requests without user input for quick testing\"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    # Configure tracing\n",
    "    connection_string = os.getenv('APPLICATIONINSIGHTS_CONNECTION_STRING')\n",
    "    if connection_string:\n",
    "        configure_azure_monitor(connection_string=connection_string)\n",
    "    else:\n",
    "        from opentelemetry.sdk.trace import TracerProvider\n",
    "        from opentelemetry.sdk.trace.export import ConsoleSpanExporter, BatchSpanProcessor\n",
    "        trace.set_tracer_provider(TracerProvider())\n",
    "        trace.get_tracer_provider().add_span_processor(\n",
    "            BatchSpanProcessor(ConsoleSpanExporter())\n",
    "        )\n",
    "    \n",
    "    tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    # Sample data for automated testing\n",
    "    test_inputs = [\n",
    "        (\"hello world\", \"text_transformation\"),\n",
    "        (\"process this data\", \"data_processing\"),\n",
    "        (\"calculate quarterly revenue\", \"business_logic\"),\n",
    "        (\"analyze customer feedback\", \"custom_workflow\"),\n",
    "        (\"transform user input\", \"text_transformation\")\n",
    "    ]\n",
    "    \n",
    "    with tracer.start_as_current_span(\"automated_client_session\") as session_span:\n",
    "        session_span.set_attribute(\"session.mode\", \"automated\")\n",
    "        session_span.set_attribute(\"session.test_data_count\", len(test_inputs))\n",
    "        \n",
    "        workflow = (\n",
    "            WorkflowBuilder()\n",
    "            .add_edge(StartExecutor(id=\"start\"), EndExecutor(id=\"end\"))\n",
    "            .set_start_executor(\"start\")\n",
    "            .build()\n",
    "        )\n",
    "        \n",
    "        print(\"ü§ñ Running automated client demo...\")\n",
    "        \n",
    "        for i, (input_text, request_type) in enumerate(test_inputs):\n",
    "            with tracer.start_as_current_span(f\"automated_request_{i+1}\") as request_span:\n",
    "                # Add simulated client metadata\n",
    "                request_span.set_attribute(\"client.id\", f\"client_{random.randint(1000, 9999)}\")\n",
    "                request_span.set_attribute(\"client.request_id\", f\"req_{i+1}_{int(time.time())}\")\n",
    "                request_span.set_attribute(\"request.input\", input_text)\n",
    "                request_span.set_attribute(\"request.type\", request_type)\n",
    "                request_span.set_attribute(\"request.automated\", True)\n",
    "                \n",
    "                # Add business context\n",
    "                if request_type == \"business_logic\":\n",
    "                    request_span.set_attribute(\"business.department\", random.choice([\"finance\", \"marketing\", \"operations\"]))\n",
    "                    request_span.set_attribute(\"business.priority\", random.choice([\"high\", \"medium\", \"low\"]))\n",
    "                elif request_type == \"data_processing\":\n",
    "                    request_span.set_attribute(\"data.size_bytes\", len(input_text) * 8)\n",
    "                    request_span.set_attribute(\"data.format\", \"text\")\n",
    "                \n",
    "                try:\n",
    "                    print(f\"  Processing: '{input_text}' ({request_type})\")\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # Simulate processing time variation\n",
    "                    if request_type == \"business_logic\":\n",
    "                        await asyncio.sleep(0.1)  # Simulate longer processing\n",
    "                    \n",
    "                    await workflow.run(input_text)\n",
    "                    \n",
    "                    processing_time = time.time() - start_time\n",
    "                    request_span.set_attribute(\"request.processing_time_ms\", processing_time * 1000)\n",
    "                    request_span.set_attribute(\"request.status\", \"success\")\n",
    "                    request_span.set_status(Status(StatusCode.OK))\n",
    "                    \n",
    "                    print(f\"  ‚úÖ Completed in {processing_time*1000:.2f}ms\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    request_span.set_attribute(\"request.status\", \"error\")\n",
    "                    request_span.set_attribute(\"request.error\", str(e))\n",
    "                    request_span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "                    print(f\"  ‚ùå Failed: {e}\")\n",
    "        \n",
    "        session_span.set_status(Status(StatusCode.OK))\n",
    "        print(\"üéâ Automated demo completed!\")\n",
    "\n",
    "# Run automated demo\n",
    "print(\"Running automated client requests for quick testing...\")\n",
    "await automated_client_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Client with Error Simulation\n",
    "async def advanced_client_demo():\n",
    "    \"\"\"Advanced client demo with error scenarios and complex tracing\"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    print(\"üî¨ Advanced Client Demo with Error Scenarios\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Prompt for demo type\n",
    "    demo_choice = input(\"\"\"\n",
    "Select advanced demo:\n",
    "1. Error handling simulation\n",
    "2. Performance stress test  \n",
    "3. Business workflow simulation\n",
    "4. All scenarios\n",
    "\n",
    "Enter choice (1-4): \"\"\").strip() or \"1\"\n",
    "    \n",
    "    with tracer.start_as_current_span(\"advanced_client_session\") as session_span:\n",
    "        session_span.set_attribute(\"demo.type\", demo_choice)\n",
    "        session_span.set_attribute(\"demo.advanced\", True)\n",
    "        \n",
    "        workflow = (\n",
    "            WorkflowBuilder()\n",
    "            .add_edge(StartExecutor(id=\"start\"), EndExecutor(id=\"end\"))\n",
    "            .set_start_executor(\"start\")\n",
    "            .build()\n",
    "        )\n",
    "        \n",
    "        if demo_choice in [\"1\", \"4\"]:\n",
    "            print(\"\\nüß™ Testing Error Handling...\")\n",
    "            error_scenarios = [\n",
    "                (\"normal input\", False),\n",
    "                (\"\", True),  # Empty input\n",
    "                (\"a\" * 10000, True),  # Very long input  \n",
    "                (\"special chars: !@#$%^&*()\", False),\n",
    "                (None, True)  # Null input\n",
    "            ]\n",
    "            \n",
    "            for i, (test_input, should_error) in enumerate(error_scenarios):\n",
    "                with tracer.start_as_current_span(f\"error_test_{i+1}\") as error_span:\n",
    "                    error_span.set_attribute(\"test.input\", str(test_input) if test_input else \"None\")\n",
    "                    error_span.set_attribute(\"test.expected_error\", should_error)\n",
    "                    error_span.set_attribute(\"test.scenario\", \"error_handling\")\n",
    "                    \n",
    "                    try:\n",
    "                        if test_input is None:\n",
    "                            raise ValueError(\"Null input not allowed\")\n",
    "                        if len(str(test_input)) > 1000:\n",
    "                            raise ValueError(\"Input too long\")\n",
    "                        if test_input == \"\":\n",
    "                            raise ValueError(\"Empty input not allowed\")\n",
    "                            \n",
    "                        await workflow.run(str(test_input))\n",
    "                        error_span.set_attribute(\"test.result\", \"success\")\n",
    "                        error_span.set_status(Status(StatusCode.OK))\n",
    "                        print(f\"  ‚úÖ Test {i+1}: Success with '{str(test_input)[:20]}...'\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        error_span.set_attribute(\"test.result\", \"error\")\n",
    "                        error_span.set_attribute(\"test.error_message\", str(e))\n",
    "                        error_span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "                        error_span.record_exception(e)\n",
    "                        print(f\"  ‚ùå Test {i+1}: Expected error - {e}\")\n",
    "        \n",
    "        if demo_choice in [\"2\", \"4\"]:\n",
    "            print(\"\\n‚ö° Performance Stress Test...\")\n",
    "            num_concurrent = 3\n",
    "            \n",
    "            async def stress_request(request_id: int):\n",
    "                with tracer.start_as_current_span(f\"stress_request_{request_id}\") as stress_span:\n",
    "                    stress_span.set_attribute(\"stress.request_id\", request_id)\n",
    "                    stress_span.set_attribute(\"stress.concurrent_requests\", num_concurrent)\n",
    "                    \n",
    "                    # Simulate random processing time\n",
    "                    processing_delay = random.uniform(0.1, 0.5)\n",
    "                    stress_span.set_attribute(\"stress.simulated_delay\", processing_delay)\n",
    "                    \n",
    "                    await asyncio.sleep(processing_delay)\n",
    "                    await workflow.run(f\"Stress test message {request_id}\")\n",
    "                    \n",
    "                    stress_span.set_status(Status(StatusCode.OK))\n",
    "                    return request_id\n",
    "            \n",
    "            # Run concurrent requests\n",
    "            start_time = time.time()\n",
    "            tasks = [stress_request(i) for i in range(num_concurrent)]\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            session_span.set_attribute(\"stress.total_time\", end_time - start_time)\n",
    "            session_span.set_attribute(\"stress.concurrent_count\", num_concurrent)\n",
    "            print(f\"  üèÅ Completed {len(results)} concurrent requests in {end_time - start_time:.2f}s\")\n",
    "        \n",
    "        if demo_choice in [\"3\", \"4\"]:\n",
    "            print(\"\\nüíº Business Workflow Simulation...\")\n",
    "            business_workflows = [\n",
    "                (\"process customer order\", \"order_management\", \"high\"),\n",
    "                (\"generate monthly report\", \"reporting\", \"medium\"),\n",
    "                (\"validate user credentials\", \"authentication\", \"high\"),\n",
    "                (\"backup user data\", \"data_management\", \"low\")\n",
    "            ]\n",
    "            \n",
    "            for workflow_name, category, priority in business_workflows:\n",
    "                with tracer.start_as_current_span(f\"business_workflow\") as biz_span:\n",
    "                    biz_span.set_attribute(\"business.workflow_name\", workflow_name)\n",
    "                    biz_span.set_attribute(\"business.category\", category)\n",
    "                    biz_span.set_attribute(\"business.priority\", priority)\n",
    "                    biz_span.set_attribute(\"business.user_id\", f\"user_{random.randint(1000, 9999)}\")\n",
    "                    biz_span.set_attribute(\"business.department\", random.choice([\"sales\", \"finance\", \"IT\", \"HR\"]))\n",
    "                    \n",
    "                    # Simulate business logic complexity\n",
    "                    if priority == \"high\":\n",
    "                        biz_span.set_attribute(\"business.sla_seconds\", 5)\n",
    "                    elif priority == \"medium\":\n",
    "                        biz_span.set_attribute(\"business.sla_seconds\", 30)\n",
    "                    else:\n",
    "                        biz_span.set_attribute(\"business.sla_seconds\", 300)\n",
    "                    \n",
    "                    await workflow.run(workflow_name)\n",
    "                    biz_span.set_status(Status(StatusCode.OK))\n",
    "                    print(f\"  üíº Completed: {workflow_name} ({priority} priority)\")\n",
    "        \n",
    "        session_span.set_status(Status(StatusCode.OK))\n",
    "        print(\"\\nüéâ Advanced demo completed!\")\n",
    "\n",
    "# Interactive choice for advanced demo\n",
    "run_advanced = input(\"\\nWould you like to run the advanced client demo? (y/n): \").lower().startswith('y')\n",
    "if run_advanced:\n",
    "    await advanced_client_demo()\n",
    "else:\n",
    "    print(\"Skipping advanced demo. You can run it later by executing the cell above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Client Request Features\n",
    "\n",
    "Your notebook now includes three different client simulation approaches:\n",
    "\n",
    "### üéØ Interactive Client (`main_with_client()`)\n",
    "- **User Input**: Prompts for number of requests and request types\n",
    "- **Request Types**: Text transformation, data processing, business logic, custom workflows\n",
    "- **Real-time Feedback**: Shows processing status and timing for each request\n",
    "- **Session Metrics**: Tracks success rates, average processing time, and total requests\n",
    "\n",
    "### ü§ñ Automated Client (`automated_client_demo()`)\n",
    "- **Predefined Test Data**: Uses sample inputs for quick testing\n",
    "- **Simulated Metadata**: Adds client IDs, request IDs, and business context\n",
    "- **Performance Variation**: Simulates different processing times based on request type\n",
    "- **Consistent Testing**: Great for reproducible testing scenarios\n",
    "\n",
    "### üî¨ Advanced Client (`advanced_client_demo()`)\n",
    "- **Error Scenarios**: Tests handling of null, empty, and oversized inputs\n",
    "- **Stress Testing**: Runs concurrent requests to test performance\n",
    "- **Business Workflows**: Simulates real business processes with priorities and SLAs\n",
    "- **Comprehensive Tracing**: Includes detailed business context and error handling\n",
    "\n",
    "### üìä Traced Attributes Include:\n",
    "- **Request Level**: Input data, processing time, status, error messages\n",
    "- **Session Level**: Total requests, success rates, average performance\n",
    "- **Business Level**: Department, priority, SLA requirements, user context\n",
    "- **Technical Level**: Client IDs, request IDs, processing delays, error types\n",
    "\n",
    "All requests create detailed spans that can be viewed in Azure Application Insights or console output for debugging and monitoring purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "To use Azure Application Insights, set the following environment variable:\n",
    "\n",
    "```bash\n",
    "APPLICATIONINSIGHTS_CONNECTION_STRING=\"InstrumentationKey=your-key;IngestionEndpoint=https://your-region.in.applicationinsights.azure.com/\"\n",
    "```\n",
    "\n",
    "If this environment variable is not set, the code will fall back to console output for tracing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Check current environment variables\n",
    "print(\"Current tracing configuration:\")\n",
    "app_insights_conn = os.getenv('APPLICATIONINSIGHTS_CONNECTION_STRING')\n",
    "if app_insights_conn:\n",
    "    print(f\"Application Insights: Configured (Connection string starts with: {app_insights_conn[:50]}...)\")\n",
    "else:\n",
    "    print(\"Application Insights: Not configured (using console output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Foundry Portal Tracing Setup\n",
    "\n",
    "**Issue**: You see traces in Application Insights but not in AI Foundry portal because they use different tracing endpoints.\n",
    "\n",
    "- **Application Insights**: Uses Azure Monitor with `configure_azure_monitor()`\n",
    "- **AI Foundry Portal**: Uses local OpenTelemetry collector at `http://localhost:4317`\n",
    "\n",
    "The solution is to configure the agent framework's built-in observability setup instead of Azure Monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Foundry Portal Tracing Configuration\n",
    "async def main_with_foundry_tracing() -> None:\n",
    "    \"\"\"Configure tracing for AI Foundry portal instead of Azure Monitor\"\"\"\n",
    "    import time\n",
    "    \n",
    "    # Use agent framework's built-in observability setup for AI Foundry\n",
    "    from agent_framework.observability import setup_observability\n",
    "    \n",
    "    print(\"üîß Configuring tracing for AI Foundry portal...\")\n",
    "    \n",
    "    # Configure for AI Toolkit's local OpenTelemetry collector\n",
    "    setup_observability(\n",
    "        otlp_endpoint=\"http://localhost:4317\",  # AI Toolkit gRPC endpoint\n",
    "        enable_sensitive_data=True  # Enable capturing prompts and completions\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ AI Foundry tracing configured successfully!\")\n",
    "    print(\"üìä Traces will now appear in the AI Foundry portal tracing tab\")\n",
    "    \n",
    "    # Get tracer\n",
    "    tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    # Get user input for testing\n",
    "    print(\"\\nüéØ AI Foundry Tracing Demo\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    test_message = input(\"Enter a message to process: \") or \"AI Foundry tracing test\"\n",
    "    \n",
    "    with tracer.start_as_current_span(\"ai_foundry_workflow_execution\") as workflow_span:\n",
    "        workflow_span.set_attribute(\"foundry.portal\", \"enabled\")\n",
    "        workflow_span.set_attribute(\"workflow.type\", \"ai_foundry_demo\")\n",
    "        workflow_span.set_attribute(\"input.message\", test_message)\n",
    "        workflow_span.set_attribute(\"timestamp\", time.time())\n",
    "        \n",
    "        try:\n",
    "            # Build workflow\n",
    "            with tracer.start_as_current_span(\"foundry_workflow_build\") as build_span:\n",
    "                workflow = (\n",
    "                    WorkflowBuilder()\n",
    "                    .add_edge(StartExecutor(id=\"start\"), EndExecutor(id=\"end\"))\n",
    "                    .set_start_executor(\"start\")\n",
    "                    .build()\n",
    "                )\n",
    "                build_span.set_attribute(\"workflow.nodes\", 2)\n",
    "                build_span.set_status(Status(StatusCode.OK))\n",
    "                print(\"‚úÖ Workflow built for AI Foundry\")\n",
    "            \n",
    "            # Run workflow\n",
    "            with tracer.start_as_current_span(\"foundry_workflow_run\") as run_span:\n",
    "                run_span.set_attribute(\"execution.mode\", \"ai_foundry\")\n",
    "                run_span.set_attribute(\"input.text\", test_message)\n",
    "                \n",
    "                print(f\"üöÄ Processing: '{test_message}'\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                await workflow.run(test_message)\n",
    "                \n",
    "                processing_time = time.time() - start_time\n",
    "                run_span.set_attribute(\"processing.time_ms\", processing_time * 1000)\n",
    "                run_span.set_status(Status(StatusCode.OK))\n",
    "                \n",
    "                print(f\"‚úÖ Completed in {processing_time*1000:.2f}ms\")\n",
    "            \n",
    "            workflow_span.set_status(Status(StatusCode.OK))\n",
    "            print(\"\\nüéâ AI Foundry tracing demo completed!\")\n",
    "            print(\"üìä Check the AI Foundry portal tracing tab to see the traces\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            workflow_span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            workflow_span.record_exception(e)\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "\n",
    "# Run AI Foundry tracing demo\n",
    "print(\"üîß Setting up tracing for AI Foundry portal...\")\n",
    "await main_with_foundry_tracing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Tracing Destinations Demo\n",
    "async def dual_tracing_demo():\n",
    "    \"\"\"Demo showing how to send traces to both Azure Monitor and AI Foundry\"\"\"\n",
    "    import time\n",
    "    from opentelemetry.sdk.trace import TracerProvider\n",
    "    from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "    from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "    from azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter\n",
    "    \n",
    "    print(\"üîÑ Setting up dual tracing (Azure Monitor + AI Foundry)...\")\n",
    "    \n",
    "    # Create tracer provider\n",
    "    tracer_provider = TracerProvider()\n",
    "    \n",
    "    # Add AI Foundry OTLP exporter\n",
    "    otlp_exporter = OTLPSpanExporter(endpoint=\"http://localhost:4317\")\n",
    "    tracer_provider.add_span_processor(BatchSpanProcessor(otlp_exporter))\n",
    "    print(\"‚úÖ AI Foundry OTLP exporter configured\")\n",
    "    \n",
    "    # Add Azure Monitor exporter if connection string is available\n",
    "    app_insights_conn = os.getenv('APPLICATIONINSIGHTS_CONNECTION_STRING')\n",
    "    if app_insights_conn:\n",
    "        azure_exporter = AzureMonitorTraceExporter(connection_string=app_insights_conn)\n",
    "        tracer_provider.add_span_processor(BatchSpanProcessor(azure_exporter))\n",
    "        print(\"‚úÖ Azure Monitor exporter configured\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Azure Monitor not configured (no connection string)\")\n",
    "    \n",
    "    # Set the tracer provider\n",
    "    trace.set_tracer_provider(tracer_provider)\n",
    "    tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    # Demo with dual tracing\n",
    "    test_message = input(\"\\nEnter message for dual tracing demo: \") or \"Dual tracing test\"\n",
    "    \n",
    "    with tracer.start_as_current_span(\"dual_tracing_workflow\") as workflow_span:\n",
    "        workflow_span.set_attribute(\"tracing.destinations\", \"azure_monitor,ai_foundry\")\n",
    "        workflow_span.set_attribute(\"demo.type\", \"dual_tracing\")\n",
    "        workflow_span.set_attribute(\"input.message\", test_message)\n",
    "        \n",
    "        try:\n",
    "            workflow = (\n",
    "                WorkflowBuilder()\n",
    "                .add_edge(StartExecutor(id=\"start\"), EndExecutor(id=\"end\"))\n",
    "                .set_start_executor(\"start\")\n",
    "                .build()\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nüöÄ Processing '{test_message}' with dual tracing...\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            with tracer.start_as_current_span(\"dual_workflow_execution\") as exec_span:\n",
    "                exec_span.set_attribute(\"execution.dual_trace\", True)\n",
    "                await workflow.run(test_message)\n",
    "                \n",
    "                processing_time = time.time() - start_time\n",
    "                exec_span.set_attribute(\"processing.time_ms\", processing_time * 1000)\n",
    "                exec_span.set_status(Status(StatusCode.OK))\n",
    "            \n",
    "            workflow_span.set_status(Status(StatusCode.OK))\n",
    "            \n",
    "            print(f\"‚úÖ Completed in {processing_time*1000:.2f}ms\")\n",
    "            print(\"\\nüìä Traces sent to:\")\n",
    "            print(\"   ‚Ä¢ AI Foundry portal (localhost:4317)\")\n",
    "            if app_insights_conn:\n",
    "                print(\"   ‚Ä¢ Azure Application Insights\")\n",
    "            print(\"\\nüîç Check both locations to see the traces!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            workflow_span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            workflow_span.record_exception(e)\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            raise\n",
    "\n",
    "# Choice for dual tracing\n",
    "setup_dual = input(\"\\nWould you like to set up dual tracing (Azure + AI Foundry)? (y/n): \").lower().startswith('y')\n",
    "if setup_dual:\n",
    "    await dual_tracing_demo()\n",
    "else:\n",
    "    print(\"Skipping dual tracing setup. Use the cell above to run it later.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why You Don't See Traces in AI Foundry Portal\n",
    "\n",
    "### The Problem:\n",
    "Your code uses **Azure Monitor tracing** (`configure_azure_monitor()`), which sends traces to Azure Application Insights. However, the **AI Foundry portal tracing tab** expects traces to be sent to its local OpenTelemetry collector.\n",
    "\n",
    "### Two Different Tracing Systems:\n",
    "\n",
    "1. **Azure Application Insights** (what you're currently using):\n",
    "   - Endpoint: Azure cloud service\n",
    "   - Configuration: `configure_azure_monitor(connection_string=...)`\n",
    "   - View traces: Azure portal ‚Üí Application Insights ‚Üí Transaction search\n",
    "\n",
    "2. **AI Foundry Portal** (what you need for the portal):\n",
    "   - Endpoint: `http://localhost:4317` (local OTLP collector)\n",
    "   - Configuration: `setup_observability(otlp_endpoint=\"http://localhost:4317\")`\n",
    "   - View traces: AI Foundry portal ‚Üí Tracing tab\n",
    "\n",
    "### Solutions:\n",
    "\n",
    "- **Option 1**: Use cell above for AI Foundry-only tracing\n",
    "- **Option 2**: Use dual tracing to send to both destinations\n",
    "- **Option 3**: Switch between configurations based on your needs\n",
    "\n",
    "The AI Toolkit tracing page has been opened and is ready to receive traces from the local collector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive AI Foundry Tracing Troubleshooting\n",
    "async def debug_foundry_tracing():\n",
    "    \"\"\"Comprehensive debugging to identify why traces aren't appearing in AI Foundry\"\"\"\n",
    "    import time\n",
    "    import socket\n",
    "    import requests\n",
    "    \n",
    "    print(\"üîç AI Foundry Tracing Troubleshooting\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Check if AI Toolkit tracing collector is running\n",
    "    print(\"1. Checking AI Toolkit tracing collector status...\")\n",
    "    \n",
    "    def check_port(host, port):\n",
    "        try:\n",
    "            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            sock.settimeout(2)\n",
    "            result = sock.connect_ex((host, port))\n",
    "            sock.close()\n",
    "            return result == 0\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    # Check both HTTP and gRPC endpoints\n",
    "    http_port_open = check_port('localhost', 4318)\n",
    "    grpc_port_open = check_port('localhost', 4317)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ HTTP endpoint (4318): {'‚úÖ Open' if http_port_open else '‚ùå Closed'}\")\n",
    "    print(f\"   ‚Ä¢ gRPC endpoint (4317): {'‚úÖ Open' if grpc_port_open else '‚ùå Closed'}\")\n",
    "    \n",
    "    if not (http_port_open or grpc_port_open):\n",
    "        print(\"‚ö†Ô∏è  AI Toolkit collector not running!\")\n",
    "        print(\"üí° Solution: Open AI Toolkit and start the tracing collector\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Test basic OTLP connectivity\n",
    "    print(\"\\n2. Testing OTLP connectivity...\")\n",
    "    \n",
    "    try:\n",
    "        from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "        from opentelemetry.sdk.trace import TracerProvider\n",
    "        from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "        from opentelemetry import trace\n",
    "        \n",
    "        # Create a fresh tracer provider for testing\n",
    "        test_provider = TracerProvider()\n",
    "        \n",
    "        # Try HTTP first, then gRPC\n",
    "        if http_port_open:\n",
    "            endpoint = \"http://localhost:4318/v1/traces\"\n",
    "            print(f\"   Testing HTTP endpoint: {endpoint}\")\n",
    "            from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter as HTTPExporter\n",
    "            exporter = HTTPExporter(endpoint=endpoint)\n",
    "        else:\n",
    "            endpoint = \"http://localhost:4317\"\n",
    "            print(f\"   Testing gRPC endpoint: {endpoint}\")\n",
    "            exporter = OTLPSpanExporter(endpoint=endpoint, insecure=True)\n",
    "        \n",
    "        test_provider.add_span_processor(BatchSpanProcessor(exporter))\n",
    "        trace.set_tracer_provider(test_provider)\n",
    "        \n",
    "        # Create a test span\n",
    "        tracer = trace.get_tracer(\"foundry_test\")\n",
    "        with tracer.start_as_current_span(\"connectivity_test\") as span:\n",
    "            span.set_attribute(\"test.type\", \"connectivity\")\n",
    "            span.set_attribute(\"timestamp\", time.time())\n",
    "            print(\"   ‚úÖ Test span created successfully\")\n",
    "        \n",
    "        # Force export\n",
    "        test_provider.force_flush()\n",
    "        print(\"   ‚úÖ Traces exported to AI Foundry\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå OTLP connection failed: {e}\")\n",
    "        print(\"üí° Try restarting AI Toolkit or check firewall settings\")\n",
    "        return\n",
    "    \n",
    "    # Step 3: Test with agent framework setup\n",
    "    print(\"\\n3. Testing agent framework observability setup...\")\n",
    "    \n",
    "    try:\n",
    "        from agent_framework.observability import setup_observability\n",
    "        \n",
    "        # Reset any existing configuration\n",
    "        trace.set_tracer_provider(None)\n",
    "        \n",
    "        # Configure with agent framework\n",
    "        if grpc_port_open:\n",
    "            setup_observability(\n",
    "                otlp_endpoint=\"http://localhost:4317\",\n",
    "                enable_sensitive_data=True,\n",
    "                resource_attributes={\n",
    "                    \"service.name\": \"foundry-tracing-test\",\n",
    "                    \"service.version\": \"1.0.0\"\n",
    "                }\n",
    "            )\n",
    "            print(\"   ‚úÖ Agent framework configured for gRPC\")\n",
    "        elif http_port_open:\n",
    "            setup_observability(\n",
    "                otlp_endpoint=\"http://localhost:4318/v1/traces\",\n",
    "                enable_sensitive_data=True,\n",
    "                resource_attributes={\n",
    "                    \"service.name\": \"foundry-tracing-test\",\n",
    "                    \"service.version\": \"1.0.0\"\n",
    "                }\n",
    "            )\n",
    "            print(\"   ‚úÖ Agent framework configured for HTTP\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Agent framework setup failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Step 4: Create workflow and test end-to-end\n",
    "    print(\"\\n4. Testing end-to-end workflow with AI Foundry tracing...\")\n",
    "    \n",
    "    try:\n",
    "        tracer = trace.get_tracer(\"foundry_workflow_test\")\n",
    "        \n",
    "        with tracer.start_as_current_span(\"foundry_e2e_test\") as main_span:\n",
    "            main_span.set_attribute(\"test.scenario\", \"end_to_end\")\n",
    "            main_span.set_attribute(\"foundry.enabled\", True)\n",
    "            main_span.set_attribute(\"service.name\", \"foundry-tracing-test\")\n",
    "            \n",
    "            # Build and run workflow\n",
    "            workflow = (\n",
    "                WorkflowBuilder()\n",
    "                .add_edge(StartExecutor(id=\"start\"), EndExecutor(id=\"end\"))\n",
    "                .set_start_executor(\"start\")\n",
    "                .build()\n",
    "            )\n",
    "            \n",
    "            test_input = \"AI Foundry debugging test\"\n",
    "            print(f\"   Processing: '{test_input}'\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            await workflow.run(test_input)\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            main_span.set_attribute(\"processing.time_ms\", processing_time * 1000)\n",
    "            main_span.set_attribute(\"test.status\", \"success\")\n",
    "            \n",
    "            print(f\"   ‚úÖ Workflow completed in {processing_time*1000:.2f}ms\")\n",
    "        \n",
    "        # Force flush to ensure traces are sent\n",
    "        if hasattr(trace.get_tracer_provider(), 'force_flush'):\n",
    "            trace.get_tracer_provider().force_flush()\n",
    "            print(\"   ‚úÖ Traces flushed to AI Foundry\")\n",
    "        \n",
    "        print(\"\\nüéâ All tests passed!\")\n",
    "        print(\"\\nüìä Traces should now appear in AI Foundry portal:\")\n",
    "        print(\"   1. Open AI Foundry portal\")\n",
    "        print(\"   2. Go to the Tracing tab\")\n",
    "        print(\"   3. Look for traces with service name 'foundry-tracing-test'\")\n",
    "        print(\"   4. Refresh the page if needed (traces may take 10-30 seconds)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå End-to-end test failed: {e}\")\n",
    "        print(f\"   Error details: {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# Run comprehensive debugging\n",
    "print(\"Starting comprehensive AI Foundry tracing troubleshooting...\")\n",
    "await debug_foundry_tracing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Fix: Simplified AI Foundry Tracing\n",
    "async def simple_foundry_test():\n",
    "    \"\"\"Simplified test to get traces working in AI Foundry\"\"\"\n",
    "    print(\"üöÄ Quick AI Foundry Tracing Test\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Method 1: Manual OTLP setup (most reliable)\n",
    "    from opentelemetry import trace\n",
    "    from opentelemetry.sdk.trace import TracerProvider\n",
    "    from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "    from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "    from opentelemetry.sdk.resources import Resource\n",
    "    \n",
    "    # Create resource with service name\n",
    "    resource = Resource.create({\n",
    "        \"service.name\": \"ai-foundry-test\",\n",
    "        \"service.version\": \"1.0.0\",\n",
    "        \"deployment.environment\": \"development\"\n",
    "    })\n",
    "    \n",
    "    # Create tracer provider\n",
    "    provider = TracerProvider(resource=resource)\n",
    "    \n",
    "    # Use HTTP endpoint (more reliable than gRPC)\n",
    "    http_exporter = OTLPSpanExporter(\n",
    "        endpoint=\"http://localhost:4318/v1/traces\",\n",
    "        headers={}\n",
    "    )\n",
    "    \n",
    "    provider.add_span_processor(BatchSpanProcessor(http_exporter))\n",
    "    trace.set_tracer_provider(provider)\n",
    "    \n",
    "    print(\"‚úÖ Manual OTLP configuration complete\")\n",
    "    \n",
    "    # Create and run a simple test\n",
    "    tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    with tracer.start_as_current_span(\"ai_foundry_simple_test\") as span:\n",
    "        span.set_attribute(\"test.framework\", \"manual_otlp\")\n",
    "        span.set_attribute(\"endpoint\", \"localhost:4318\")\n",
    "        span.set_attribute(\"timestamp\", int(time.time()))\n",
    "        \n",
    "        # Simple workflow test\n",
    "        print(\"Running simple workflow...\")\n",
    "        workflow = (\n",
    "            WorkflowBuilder()\n",
    "            .add_edge(StartExecutor(id=\"start\"), EndExecutor(id=\"end\"))\n",
    "            .set_start_executor(\"start\")\n",
    "            .build()\n",
    "        )\n",
    "        \n",
    "        await workflow.run(\"Simple foundry test\")\n",
    "        span.set_attribute(\"workflow.status\", \"completed\")\n",
    "        \n",
    "    # Force export\n",
    "    provider.force_flush()\n",
    "    print(\"‚úÖ Test completed and traces sent\")\n",
    "    print(\"üìä Check AI Foundry portal for 'ai-foundry-test' service\")\n",
    "\n",
    "# Run simple test\n",
    "print(\"Running simplified AI Foundry test...\")\n",
    "await simple_foundry_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Issues & Solutions for AI Foundry Tracing\n",
    "\n",
    "### üîç **Most Likely Causes:**\n",
    "\n",
    "1. **AI Toolkit Collector Not Running**\n",
    "   - The tracing collector needs to be actively running\n",
    "   - Check ports 4317 (gRPC) and 4318 (HTTP) are open\n",
    "\n",
    "2. **Wrong Endpoint Configuration** \n",
    "   - AI Foundry expects: `http://localhost:4318/v1/traces` (HTTP) or `http://localhost:4317` (gRPC)\n",
    "   - Your code was using Azure Monitor instead\n",
    "\n",
    "3. **Service Name Missing**\n",
    "   - AI Foundry groups traces by service name\n",
    "   - Without it, traces may not appear correctly\n",
    "\n",
    "4. **Trace Export Timing**\n",
    "   - Traces are batched and may take 10-30 seconds to appear\n",
    "   - Need to call `force_flush()` to ensure immediate export\n",
    "\n",
    "### ‚úÖ **Troubleshooting Steps:**\n",
    "\n",
    "Run the debugging cell above to:\n",
    "- ‚úÖ Check if AI Toolkit collector is running\n",
    "- ‚úÖ Test OTLP connectivity  \n",
    "- ‚úÖ Verify trace export\n",
    "- ‚úÖ Run end-to-end workflow test\n",
    "\n",
    "### üöÄ **Quick Test:**\n",
    "\n",
    "The simplified test cell uses the most reliable configuration:\n",
    "- HTTP endpoint (more stable than gRPC)\n",
    "- Proper service name and resource attributes\n",
    "- Force flush to ensure traces are sent immediately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Configuration (.env file)\n",
    "\n",
    "Create a `.env` file in your project root with the following tracing configurations:\n",
    "\n",
    "```bash\n",
    "# AI Foundry / AI Toolkit Tracing (Local)\n",
    "OTLP_ENDPOINT=http://localhost:4318/v1/traces\n",
    "OTLP_GRPC_ENDPOINT=http://localhost:4317\n",
    "SERVICE_NAME=ai-foundry-tracing\n",
    "SERVICE_VERSION=1.0.0\n",
    "ENVIRONMENT=development\n",
    "\n",
    "# Azure Application Insights (Cloud) - Optional\n",
    "APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=your-key;IngestionEndpoint=https://your-region.in.applicationinsights.azure.com/\n",
    "\n",
    "# Tracing Configuration\n",
    "ENABLE_SENSITIVE_DATA=true\n",
    "TRACE_EXPORT_TIMEOUT=30\n",
    "```\n",
    "\n",
    "### Environment Variable Priority:\n",
    "1. **For AI Foundry Portal**: Use `OTLP_ENDPOINT` \n",
    "2. **For Azure Monitor**: Use `APPLICATIONINSIGHTS_CONNECTION_STRING`\n",
    "3. **For Both**: Configure dual tracing in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment-based Tracing Configuration\n",
    "async def env_based_tracing():\n",
    "    \"\"\"Configure tracing based on environment variables\"\"\"\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    print(\"üîß Environment-based Tracing Configuration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load environment variables from .env file\n",
    "    try:\n",
    "        load_dotenv()\n",
    "        print(\"‚úÖ .env file loaded\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  No .env file found, using system environment variables\")\n",
    "    \n",
    "    # Get tracing configuration from environment\n",
    "    otlp_endpoint = os.getenv('OTLP_ENDPOINT', 'http://localhost:4318/v1/traces')\n",
    "    otlp_grpc_endpoint = os.getenv('OTLP_GRPC_ENDPOINT', 'http://localhost:4317')\n",
    "    service_name = os.getenv('SERVICE_NAME', 'ai-foundry-service')\n",
    "    service_version = os.getenv('SERVICE_VERSION', '1.0.0')\n",
    "    environment = os.getenv('ENVIRONMENT', 'development')\n",
    "    enable_sensitive = os.getenv('ENABLE_SENSITIVE_DATA', 'true').lower() == 'true'\n",
    "    app_insights_conn = os.getenv('APPLICATIONINSIGHTS_CONNECTION_STRING')\n",
    "    \n",
    "    print(f\"\\nüìã Configuration from environment:\")\n",
    "    print(f\"   ‚Ä¢ OTLP HTTP Endpoint: {otlp_endpoint}\")\n",
    "    print(f\"   ‚Ä¢ OTLP gRPC Endpoint: {otlp_grpc_endpoint}\")\n",
    "    print(f\"   ‚Ä¢ Service Name: {service_name}\")\n",
    "    print(f\"   ‚Ä¢ Service Version: {service_version}\")\n",
    "    print(f\"   ‚Ä¢ Environment: {environment}\")\n",
    "    print(f\"   ‚Ä¢ Sensitive Data: {enable_sensitive}\")\n",
    "    print(f\"   ‚Ä¢ Azure Monitor: {'‚úÖ Configured' if app_insights_conn else '‚ùå Not configured'}\")\n",
    "    \n",
    "    # Configure tracing based on environment\n",
    "    from opentelemetry import trace\n",
    "    from opentelemetry.sdk.trace import TracerProvider\n",
    "    from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "    from opentelemetry.sdk.resources import Resource\n",
    "    \n",
    "    # Create resource with environment variables\n",
    "    resource = Resource.create({\n",
    "        \"service.name\": service_name,\n",
    "        \"service.version\": service_version,\n",
    "        \"deployment.environment\": environment\n",
    "    })\n",
    "    \n",
    "    # Create tracer provider\n",
    "    provider = TracerProvider(resource=resource)\n",
    "    \n",
    "    # Add OTLP exporter for AI Foundry\n",
    "    try:\n",
    "        from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "        otlp_exporter = OTLPSpanExporter(endpoint=otlp_endpoint)\n",
    "        provider.add_span_processor(BatchSpanProcessor(otlp_exporter))\n",
    "        print(f\"‚úÖ OTLP exporter configured for: {otlp_endpoint}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå OTLP configuration failed: {e}\")\n",
    "    \n",
    "    # Add Azure Monitor exporter if configured\n",
    "    if app_insights_conn:\n",
    "        try:\n",
    "            from azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter\n",
    "            azure_exporter = AzureMonitorTraceExporter(connection_string=app_insights_conn)\n",
    "            provider.add_span_processor(BatchSpanProcessor(azure_exporter))\n",
    "            print(\"‚úÖ Azure Monitor exporter configured\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Azure Monitor configuration failed: {e}\")\n",
    "    \n",
    "    # Set the tracer provider\n",
    "    trace.set_tracer_provider(provider)\n",
    "    \n",
    "    # Test the configuration\n",
    "    tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    test_message = input(\"\\nEnter test message: \") or \"Environment-based tracing test\"\n",
    "    \n",
    "    with tracer.start_as_current_span(\"env_based_workflow\") as span:\n",
    "        span.set_attribute(\"config.source\", \"environment_variables\")\n",
    "        span.set_attribute(\"service.name\", service_name)\n",
    "        span.set_attribute(\"test.input\", test_message)\n",
    "        \n",
    "        try:\n",
    "            # Build and run workflow\n",
    "            workflow = (\n",
    "                WorkflowBuilder()\n",
    "                .add_edge(StartExecutor(id=\"start\"), EndExecutor(id=\"end\"))\n",
    "                .set_start_executor(\"start\")\n",
    "                .build()\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nüöÄ Processing: '{test_message}'\")\n",
    "            await workflow.run(test_message)\n",
    "            \n",
    "            span.set_attribute(\"workflow.status\", \"success\")\n",
    "            print(\"‚úÖ Workflow completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            span.set_attribute(\"workflow.status\", \"error\")\n",
    "            span.set_attribute(\"error.message\", str(e))\n",
    "            print(f\"‚ùå Workflow failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    # Force flush traces\n",
    "    provider.force_flush()\n",
    "    \n",
    "    print(f\"\\nüìä Traces sent to:\")\n",
    "    print(f\"   ‚Ä¢ AI Foundry: {otlp_endpoint}\")\n",
    "    if app_insights_conn:\n",
    "        print(\"   ‚Ä¢ Azure Monitor: Application Insights\")\n",
    "    \n",
    "    print(f\"\\nüîç Check AI Foundry portal for service: '{service_name}'\")\n",
    "\n",
    "# Run environment-based configuration\n",
    "print(\"Configuring tracing from environment variables...\")\n",
    "await env_based_tracing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
